// Package flow unicode tests ensure global text compatibility and proper handling.
// These tests validate Unicode and internationalization support:
// - RTL (Right-to-Left) text in Arabic, Hebrew
// - CJK (Chinese, Japanese, Korean) text
// - Emoji sequences and combining characters
// - Zero-width characters and special Unicode blocks
// - Mixed directionality and complex scripts
package flow

import (
	"bytes"
	"context"
	"strings"
	"testing"
)

// 1. UNICODE EDGE CASES TESTS

func TestUnicodeEdgeCases(t *testing.T) {
	t.Run("rtl_text_arabic_hebrew", func(t *testing.T) {
		// Arabic and Hebrew text
		inputs := []string{
			"# Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…\n\nÙ‡Ø°Ø§ Ù†Øµ Ø¹Ø±Ø¨ÙŠ Ù…Ø¹ **ØªÙ†Ø³ÙŠÙ‚** Ùˆ *Ù…Ø§Ø¦Ù„*.\n\n- Ù‚Ø§Ø¦Ù…Ø©\n- Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n- Ù…Ø¹ Ù†Ù‚Ø§Ø·\n",
			"# ×©×œ×•× ×¢×•×œ×\n\n×–×” ×˜×§×¡×˜ ×¢×‘×¨×™ ×¢× **×”×“×’×©×”** ×•*× ×˜×•×™*.\n\n- ×¨×©×™××”\n- ×‘×¢×‘×¨×™×ª\n- ×¢× × ×§×•×“×•×ª\n",
		}

		for _, input := range inputs {
			var buf bytes.Buffer
			err := Flow(context.Background(), strings.NewReader(input), &buf, 1024, passthroughRenderer)
			if err != nil {
				t.Fatalf("Failed on RTL text: %v", err)
			}

			output := buf.String()
			// Glamour formats the markdown, so we check content preservation
			// not exact byte-for-byte equality
			if !strings.Contains(output, "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…") && !strings.Contains(output, "×©×œ×•× ×¢×•×œ×") {
				t.Errorf("RTL text content not preserved")
			}

			// Test with small windows too
			testFlowWithVariousSizes(t, input)
		}
	})

	t.Run("mixed_scripts", func(t *testing.T) {
		input := "# Multi-language å¤šè¯­è¨€ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹\n\n" +
			"English text followed by ä¸­æ–‡å†…å®¹ and ×¢×‘×¨×™×ª text.\n" +
			"æ—¥æœ¬èªã‚‚å«ã‚ã¦ and Ù…Ø¹ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© too.\n" +
			"ĞšĞ¸Ñ€Ğ¸Ğ»Ğ»Ğ¸Ñ†Ğ° Ğ·Ğ´ĞµÑÑŒ Ğ¸ Î•Î»Î»Î·Î½Î¹ÎºÎ¬ also.\n"

		testFlowWithVariousSizes(t, input)

		// Verify all scripts preserved
		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 100, passthroughRenderer)
		if err != nil {
			t.Fatalf("Mixed scripts failed: %v", err)
		}

		output := buf.String()
		// Check each script is present
		scripts := []string{"Multi-language", "å¤šè¯­è¨€", "Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª", "Ğ¼ÑƒĞ»ÑŒÑ‚Ğ¸ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¹",
			"ä¸­æ–‡å†…å®¹", "×¢×‘×¨×™×ª", "æ—¥æœ¬èª", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "ĞšĞ¸Ñ€Ğ¸Ğ»Ğ»Ğ¸Ñ†Ğ°", "Î•Î»Î»Î·Î½Î¹ÎºÎ¬"}
		for _, script := range scripts {
			if !strings.Contains(output, script) {
				t.Errorf("Script %q not found in output", script)
			}
		}
	})

	t.Run("emoji_clusters", func(t *testing.T) {
		// Various emoji including complex clusters
		input := "# Emoji Test ğŸ‰\n\n" +
			"Simple: ğŸ˜€ ğŸ˜ƒ ğŸ˜„ ğŸ˜\n" +
			"Flags: ğŸ‡ºğŸ‡¸ ğŸ‡¬ğŸ‡§ ğŸ‡¯ğŸ‡µ ğŸ‡¨ğŸ‡³\n" +
			"Family: ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦\n" +
			"Professions: ğŸ‘¨â€ğŸ’» ğŸ‘©â€ğŸ”¬ ğŸ‘¨â€ğŸ¨\n" +
			"Skin tones: ğŸ‘‹ğŸ» ğŸ‘‹ğŸ½ ğŸ‘‹ğŸ¿\n" +
			"Combined: ğŸ‘¨ğŸ»â€ğŸ’» ğŸ‘©ğŸ½â€ğŸ”¬\n"

		testFlowWithVariousSizes(t, input)

		// Verify emoji preserved
		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 10, passthroughRenderer)
		if err != nil {
			t.Fatalf("Emoji test failed: %v", err)
		}

		// Glamour formats text, just verify emoji are present
		if !strings.Contains(buf.String(), "ğŸ‰") || !strings.Contains(buf.String(), "ğŸ‘¨") {
			t.Error("Emoji content not found")
		}
	})

	t.Run("zero_width_characters", func(t *testing.T) {
		// Zero-width space (U+200B), Zero-width joiner (U+200D), Zero-width non-joiner (U+200C)
		input := "Word\u200Bbreak\n" + // ZWSP for word break
			"Ù„Ø§\u200Carial\n" + // ZWNJ in Arabic/Latin mix
			"ğŸ‘¨\u200DğŸ‘©\u200DğŸ‘§\u200DğŸ‘¦\n" + // ZWJ in emoji family
			"a\u200Db\u200Dc\n" + // ZWJ between letters
			"test\u200B\u200B\u200Bmultiple\n" // Multiple ZWSP

		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 1, passthroughRenderer)
		if err != nil {
			t.Fatalf("Zero-width char test failed: %v", err)
		}

		// Glamour may process zero-width characters
		// Just verify visible text is present
		if !strings.Contains(buf.String(), "Word") || !strings.Contains(buf.String(), "break") {
			t.Error("Text around zero-width chars not found")
		}

		// Test with various window sizes
		testFlowWithVariousSizes(t, input)
	})

	t.Run("combining_marks", func(t *testing.T) {
		// Test both precomposed and decomposed forms
		input := "# Combining Marks\n\n" +
			"Precomposed: cafÃ© naÃ¯ve rÃ©sumÃ©\n" +
			"Decomposed: cafe\u0301 nai\u0308ve re\u0301sume\u0301\n" + // Using combining marks
			"Multiple marks: a\u0300\u0301\u0302\u0303\u0304\n" + // a with 5 combining marks
			"Thai: à¸à¸³ à¸”à¸µ à¸¡à¸²à¸\n" + // Thai with combining marks
			"Vietnamese: Tiáº¿ng Viá»‡t\n"

		testFlowWithVariousSizes(t, input)

		// Verify marks preserved
		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 10, passthroughRenderer)
		if err != nil {
			t.Fatalf("Combining marks test failed: %v", err)
		}

		// Glamour may normalize combining marks
		// Just verify base text is present
		if !strings.Contains(buf.String(), "cafÃ©") || !strings.Contains(buf.String(), "Combining Marks") {
			t.Error("Content with combining marks not found")
		}
	})
}

// 2. CHARACTER ENCODING TESTS

func TestUnicodeCharacterEncoding(t *testing.T) {
	t.Run("utf8_bom", func(t *testing.T) {
		// UTF-8 BOM (Byte Order Mark)
		input := "\xEF\xBB\xBF# Document with BOM\n\nContent after BOM.\n"

		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 100, passthroughRenderer)
		if err != nil {
			t.Fatalf("BOM handling failed: %v", err)
		}

		// Glamour may handle BOM differently
		// Just verify content is preserved
		if !strings.Contains(buf.String(), "Document with BOM") || !strings.Contains(buf.String(), "Content after BOM") {
			t.Error("Content not preserved with BOM")
		}
	})

	t.Run("invalid_utf8_sequences", func(t *testing.T) {
		// Invalid UTF-8 bytes
		invalidBytes := []byte{0x80, 0x81, 0xFF, 0xFE, 0xFD}
		input := append([]byte("Valid start\n"), invalidBytes...)
		input = append(input, []byte("\nValid end")...)

		var buf bytes.Buffer
		err := Flow(context.Background(), bytes.NewReader(input), &buf, 100, passthroughRenderer)
		if err != nil {
			t.Logf("Invalid UTF-8 handling: %v", err)
		}

		// Should handle gracefully
		if buf.Len() == 0 {
			t.Error("Expected some output for invalid UTF-8")
		}
	})

	t.Run("replacement_character", func(t *testing.T) {
		// Unicode replacement character U+FFFD
		input := "Text with ï¿½ replacement ï¿½ characters\n"

		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 100, passthroughRenderer)
		if err != nil {
			t.Fatalf("Replacement char test failed: %v", err)
		}

		// Glamour formats the text, verify replacement chars are present
		if !strings.Contains(buf.String(), "replacement") {
			t.Error("Content with replacement characters not preserved")
		}
	})

	t.Run("multi_byte_boundaries", func(t *testing.T) {
		// Test multi-byte characters at window boundaries
		// Using Chinese characters (3 bytes each in UTF-8)
		input := "ä¸­æ–‡å­—ç¬¦æµ‹è¯•æ–‡æœ¬\næ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ\ní•œê¸€ í…ìŠ¤íŠ¸\n"

		// Test with 1-byte window (most challenging)
		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 1, passthroughRenderer)
		if err != nil {
			t.Fatalf("Multi-byte boundary test failed: %v", err)
		}

		// Glamour formats the text, verify key content is preserved
		if !strings.Contains(buf.String(), "ä¸­æ–‡") || !strings.Contains(buf.String(), "æ—¥æœ¬èª") {
			t.Error("Multi-byte characters not preserved at boundaries")
		}

		// Test with windows that might split multi-byte chars
		for _, window := range []int64{2, 3, 5, 7, 11} {
			buf.Reset()
			err := Flow(context.Background(), strings.NewReader(input), &buf, window, passthroughRenderer)
			if err != nil {
				t.Errorf("Failed with window=%d: %v", window, err)
			}
			// Just verify content is present
			if !strings.Contains(buf.String(), "ä¸­æ–‡") {
				t.Errorf("Multi-byte chars not found with window=%d", window)
			}
		}
	})

	t.Run("surrogate_pairs", func(t *testing.T) {
		// Emoji and characters outside BMP use surrogate pairs in UTF-16
		// but are valid 4-byte sequences in UTF-8
		input := "Mathematical: ğ• ğ• ğ•‘\n" + // Mathematical double-struck
			"Ancient: ğŒ€ ğŒ ğŒ‚\n" + // Old Italic
			"Emoji: ğŸ˜€ ğŸ‰ ğŸš€\n" + // Emoji (also 4-byte UTF-8)
			"Egyptian: ğ“€€ ğ“€ ğ“€‚\n" // Egyptian hieroglyphs

		testFlowWithVariousSizes(t, input)
	})
}

// 3. TEXT DIRECTION TESTS

func TestUnicodeTextDirection(t *testing.T) {
	t.Run("pure_rtl_markdown", func(t *testing.T) {
		input := "# Ø¹Ù†ÙˆØ§Ù† Ø±Ø¦ÙŠØ³ÙŠ\n\n" +
			"## Ø¹Ù†ÙˆØ§Ù† ÙØ±Ø¹ÙŠ\n\n" +
			"ÙÙ‚Ø±Ø© Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ **Ù†Øµ ØºØ§Ù…Ù‚** Ùˆ *Ù†Øµ Ù…Ø§Ø¦Ù„*.\n\n" +
			"### Ù‚Ø§Ø¦Ù…Ø©:\n" +
			"- Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø£ÙˆÙ„\n" +
			"- Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø«Ø§Ù†ÙŠ\n" +
			"- Ø§Ù„Ø¹Ù†ØµØ± Ø§Ù„Ø«Ø§Ù„Ø«\n\n" +
			"[Ø±Ø§Ø¨Ø·](https://example.com)\n"

		testFlowWithVariousSizes(t, input)
	})

	t.Run("mixed_ltr_rtl", func(t *testing.T) {
		input := "# Mixed Direction Text\n\n" +
			"The Hebrew word ×©×œ×•× means peace.\n" +
			"The Arabic phrase Ù…Ø±Ø­Ø¨Ø§ Ø¨Ùƒ means welcome.\n" +
			"Numbers 123 in Arabic: Ù¡Ù¢Ù£\n" +
			"Code: `console.log('×©×œ×•×');`\n"

		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 100, passthroughRenderer)
		if err != nil {
			t.Fatalf("Mixed LTR/RTL failed: %v", err)
		}

		// Glamour formats text, verify key content is preserved
		if !strings.Contains(buf.String(), "×©×œ×•×") || !strings.Contains(buf.String(), "Ù…Ø±Ø­Ø¨Ø§") {
			t.Error("Mixed direction text content not found")
		}
	})

	t.Run("bidirectional_overrides", func(t *testing.T) {
		// LRO (U+202D), RLO (U+202E), PDF (U+202C)
		input := "Normal text\n" +
			"\u202Dforced LTR text\u202C\n" +
			"\u202Eforced RTL text\u202C\n" +
			"Mixed: \u202Dabc\u202Edef\u202Cghi\n"

		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 10, passthroughRenderer)
		if err != nil {
			t.Fatalf("Bidi override test failed: %v", err)
		}

		// Glamour may process bidi overrides
		// Just verify visible text is present
		if !strings.Contains(buf.String(), "Normal text") || !strings.Contains(buf.String(), "forced") {
			t.Error("Text with bidi overrides not found")
		}
	})

	t.Run("rtl_in_code_blocks", func(t *testing.T) {
		input := "```javascript\n" +
			"// ØªØ¹Ù„ÙŠÙ‚ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n" +
			"const greeting = '×©×œ×•× ×¢×•×œ×';\n" +
			"console.log(greeting);\n" +
			"```\n"

		testFlowWithVariousSizes(t, input)
	})

	t.Run("direction_marks_in_links", func(t *testing.T) {
		// LRM (U+200E) and RLM (U+200F)
		input := "[English \u200Elink](url)\n" +
			"[Ø¹Ø±Ø¨ÙŠ \u200FØ±Ø§Ø¨Ø·](url)\n" +
			"Mixed: [EN \u200E×¢×‘×¨×™×ª \u200FØ§Ù„Ø¹Ø±Ø¨ÙŠØ©](url)\n"

		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 10, passthroughRenderer)
		if err != nil {
			t.Fatalf("Direction marks test failed: %v", err)
		}

		// Glamour formats links, verify content is present
		if !strings.Contains(buf.String(), "English") || !strings.Contains(buf.String(), "Ø¹Ø±Ø¨ÙŠ") {
			t.Error("Direction marks content not found")
		}
	})
}

// 4. EXTREME UNICODE TESTS

func TestUnicodeExtreme(t *testing.T) {
	t.Run("max_combining_marks", func(t *testing.T) {
		// Create a character with many combining marks
		var input strings.Builder
		input.WriteString("a")
		// Add 50 different combining marks (there are ~350 total)
		combiningMarks := []rune{
			0x0300, 0x0301, 0x0302, 0x0303, 0x0304, 0x0305, 0x0306, 0x0307,
			0x0308, 0x0309, 0x030A, 0x030B, 0x030C, 0x030D, 0x030E, 0x030F,
			0x0310, 0x0311, 0x0312, 0x0313, 0x0314, 0x0315, 0x0316, 0x0317,
			0x0318, 0x0319, 0x031A, 0x031B, 0x031C, 0x031D, 0x031E, 0x031F,
			0x0320, 0x0321, 0x0322, 0x0323, 0x0324, 0x0325, 0x0326, 0x0327,
			0x0328, 0x0329, 0x032A, 0x032B, 0x032C, 0x032D, 0x032E, 0x032F,
			0x0330, 0x0331,
		}
		for _, mark := range combiningMarks {
			input.WriteRune(mark)
		}
		input.WriteString("\n")

		inputStr := input.String()
		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(inputStr), &buf, 1, passthroughRenderer)
		if err != nil {
			t.Fatalf("Max combining marks test failed: %v", err)
		}

		// Glamour may normalize combining marks
		// Just verify base character is present
		if !strings.Contains(buf.String(), "a") {
			t.Error("Base character not found in output")
		}
	})

	t.Run("complex_grapheme_clusters", func(t *testing.T) {
		// Complex emoji with skin tone and gender modifiers
		input := "ğŸ‘¨ğŸ»â€ğŸ’» Woman technologist: ğŸ‘©ğŸ½â€ğŸ’»\n" +
			"Family: ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦\n" +
			"Flag: ğŸ´ó §ó ¢ó ³ó £ó ´ó ¿\n" + // Scotland flag with tag characters
			"Rainbow flag: ğŸ³ï¸â€ğŸŒˆ\n" +
			"Keycap: 3ï¸âƒ£ #ï¸âƒ£ *ï¸âƒ£\n"

		testFlowWithVariousSizes(t, input)
	})

	t.Run("fullwidth_characters", func(t *testing.T) {
		input := "# ï¼¦ï½•ï½Œï½Œï½—ï½‰ï½„ï½”ï½ˆã€€ï¼´ï½…ï½˜ï½”\n\n" +
			"ï¼¨ï½…ï½Œï½Œï½ã€€ï¼·ï½ï½’ï½Œï½„ï¼\n" +
			"Numbers:ã€€ï¼‘ï¼’ï¼“ï¼”ï¼•\n" +
			"Mixed: Normal and ï¼¦ï½•ï½Œï½Œï½—ï½‰ï½„ï½”ï½ˆ text\n"

		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 10, passthroughRenderer)
		if err != nil {
			t.Fatalf("Fullwidth test failed: %v", err)
		}

		// Glamour formats text, verify fullwidth content
		if !strings.Contains(buf.String(), "ï¼¦ï½•ï½Œï½Œï½—ï½‰ï½„ï½”ï½ˆ") {
			t.Error("Fullwidth content not found")
		}
	})

	t.Run("mathematical_symbols", func(t *testing.T) {
		input := "# Mathematical Notation\n\n" +
			"âˆ€x âˆˆ â„: xÂ² â‰¥ 0\n" +
			"âˆ‘áµ¢â‚Œâ‚â¿ i = n(n+1)/2\n" +
			"âˆ«â‚€^âˆ eâ»Ë£ dx = 1\n" +
			"âˆš2 â‰ˆ 1.414\n" +
			"âˆ â‰  -âˆ\n" +
			"ğ”¸ğ”¹â„‚ğ”»ğ”¼ğ”½ğ”¾â„ğ•€ğ•ğ•‚ğ•ƒğ•„â„•ğ•†â„™â„šâ„ğ•Šğ•‹ğ•Œğ•ğ•ğ•ğ•â„¤\n" // Mathematical double-struck

		testFlowWithVariousSizes(t, input)
	})

	t.Run("historic_scripts", func(t *testing.T) {
		input := "# Historic Scripts\n\n" +
			"Cuneiform: ğ’€€ ğ’€ ğ’€‚ ğ’€ƒ ğ’€„\n" +
			"Egyptian hieroglyphs: ğ“€€ ğ“€ ğ“€‚ ğ“€ƒ ğ“€„\n" +
			"Linear B: ğ€€ ğ€ ğ€‚ ğ€ƒ ğ€„\n" +
			"Old Persian: ğ  ğ¡ ğ¢ ğ£ ğ¤\n" +
			"Phoenician: ğ¤€ ğ¤ ğ¤‚ ğ¤ƒ ğ¤„\n" +
			"Runic: áš  áš¡ áš¢ áš£ áš¤\n"

		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, 1, passthroughRenderer)
		if err != nil {
			t.Fatalf("Historic scripts test failed: %v", err)
		}

		// Glamour formats text, verify historic scripts are present
		if !strings.Contains(buf.String(), "Cuneiform") || !strings.Contains(buf.String(), "Egyptian") {
			t.Error("Historic script content not found")
		}

		// These are all 4-byte UTF-8 sequences, test boundaries
		testFlowWithVariousSizes(t, input)
	})
}

// Helper function to test with various window sizes
func testFlowWithVariousSizes(t *testing.T, input string) {
	windows := []int64{1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1024}

	// Extract key content to verify preservation
	// Look for non-ASCII content as markers
	var keyContent []string
	for _, r := range input {
		if r > 127 { // Non-ASCII
			keyContent = append(keyContent, string(r))
		}
	}

	for _, window := range windows {
		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, window, passthroughRenderer)

		if err != nil {
			t.Errorf("Failed with window=%d: %v", window, err)
			continue
		}

		output := buf.String()
		// Don't expect exact match with glamour formatting
		// Just verify key unicode content is preserved
		for _, content := range keyContent {
			if !strings.Contains(output, content) {
				t.Errorf("Unicode content %q not preserved with window=%d", content, window)
				break
			}
		}
	}
}

// Additional comprehensive Unicode test
func TestUnicodeComprehensive(t *testing.T) {
	// A document containing a wide variety of Unicode features
	//lint:ignore ST1018 raw string intentionally contains Unicode characters for test coverage
	input := `# ğŸŒ International Document æ–‡æ¡£ Ù…Ø³ØªÙ†Ø¯ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

## Mixed Scripts å¤šç§æ–‡å­— Ù†ØµÙˆØµ Ù…Ø®ØªÙ„Ø·Ø©

This paragraph contains English, ä¸­æ–‡, Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©, ×¢×‘×¨×™×ª, æ—¥æœ¬èª, í•œêµ­ì–´,
ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬, Ñ€ÑƒÑÑĞºĞ¸Ğ¹, à¤¹à¤¿à¤¨à¥à¤¦à¥€, à¹„à¸—à¸¢, and more.

### Emoji and Symbols ğŸ˜€

- Simple emoji: ğŸ˜€ ğŸ˜ƒ ğŸ˜„
- Flags: ğŸ‡ºğŸ‡¸ ğŸ‡¬ğŸ‡§ ğŸ‡¯ğŸ‡µ
- Families: ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦
- Professions: ğŸ‘¨â€ğŸ’» ğŸ‘©â€ğŸ”¬
- Animals: ğŸ¶ ğŸ± ğŸ­

### Mathematical âˆ‘âˆ«âˆ‚

âˆ€x âˆˆ â„: xÂ² â‰¥ 0
âˆ«â‚€^âˆ eâ»Ë£ dx = 1

### Combining Marks

cafÃ© (precomposed) vs cafe\u0301 (decomposed)
Ã± vs n\u0303
Ä… vs a\u0328

### Direction Testing

LTR: Hello World
RTL: Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…
Mixed: The word ×©×œ×•× means peace

### Special Characters

Zero-width: aâ€‹b (ZWSP)
Soft hyphen: exÂ­ample
Non-breaking space: hello world

### Full-width

ï¼¨ï½…ï½Œï½Œï½ã€€ï¼·ï½ï½’ï½Œï½„

### Historic Scripts

Cuneiform: ğ’€€ ğ’€ ğ’€‚
Egyptian: ğ“€€ ğ“€ ğ“€‚
`

	// Test with many different window sizes
	windows := []int64{1, 10, 100, 1024, 10000}
	for _, window := range windows {
		var buf bytes.Buffer
		err := Flow(context.Background(), strings.NewReader(input), &buf, window, passthroughRenderer)

		if err != nil {
			t.Errorf("Comprehensive test failed with window=%d: %v", window, err)
			continue
		}

		// Glamour formats the comprehensive unicode text
		// Just verify key sections are present
		if !strings.Contains(buf.String(), "International Document") ||
		   !strings.Contains(buf.String(), "English") ||
		   !strings.Contains(buf.String(), "ä¸­æ–‡") {
			t.Errorf("Comprehensive Unicode content not found with window=%d", window)
		}
	}
}
